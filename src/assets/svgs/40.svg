<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">


<!-- Page 40 -->
<svg x="0" y="0" width="935" height="1210" viewBox="0 0 935 1210" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
style="display: block;margin-left: auto;margin-right: auto;">
<defs>

<style type="text/css"><![CDATA[

.g1_40{
fill: #D9D9D9;
}

.s1_40{
font-size: 18.33px;
font-family: ArialNovaCond-Bold_d;
fill: #5A5A5A;
}
.s2_40{
font-size: 12.10px;
font-family: ArialNova-Light_n;
fill: #7F7F7F;
}
.s3_40{
font-size: 18.33px;
font-family: ArialNovaCond-Light_9;
fill: #5A5A5A;
}

]]></style>

</defs>
<path d="M0,0
L0,1210
L935,1210
L935,0 Z " 
fill="#FFFFFF" stroke="none" />
<text 
x="110" 
y="1106" 
dx="0,0,0,0.2" 
class="s1_40"
>40 |</text>

<text 
x="141" 
y="1106" 
dx="0,4.3,4.9,0,1.9,0,1.6,0,1.3,0,1.7,0,1.7,0,1.2,0,1.9,0,1.6,4.7,4.9,0,1.3,0,1.7,0,1.6,0,1.5,0,1.6,0,1.9,0,1.2,0,1.5,0,1.9,0,1.5,4.5,4.9,0,1.7,0,1.2,0,1.9,0,1.9,0,1.2,4.5,4.5,0,1.9,0,1.5,4.7,4.9,0,1.3,0,1.5,0,1.9,0,1.5,0,1.5,0,1.5,0,1.5,0,1.9,0,1.3,0,1.9,0,1.6,4.6,4.5,0,1.9,0,1.5,0,1.7,0,1.6,0,1.4,0,1.9,0,1.3,0,1.9,0,1.5,0,1.7,0,1.5,0,1.5,0,1.9" 
class="s2_40"
>A W e b - b a s e d T r a n s l a t i o n S y s t e m f o r M u l t i l i n g u a l C o d e - s w i t c h i n g</text>

<path d="M107.8,1086.4l719.4,0l0,-0.7l-719.4,0l0,0.7Z" class="g1_40" />
<text 
x="110" 
y="128" 
dx="0,-0.1,-0.1,0.2,-0.1,0.2,0,0.2,-0.1,0.1,0,-0.2,0.2,-0.1,0.2,0,0,-0.1,0,0.2,-0.1,0,0.2,-0.1,-0.1,0,-0.1,0,-0.2,0.2,0,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0,0.2,-0.1,-0.1,-0.1,0,0.2,-0.1,0.2,-0.1,-0.2,0.1,-0.1,-0.1,0,0,0,0.2,-0.1,-0.2,0.2,0,-0.1,0.1,-0.1,0,0.2,0.2,0,-0.1,-0.1,-0.2,0.2,-0.1,0,-0.1,0.2,-0.1,0.2,0.2,-0.1,-0.1,0,0.2,-0.1,-0.1,0.2,-0.1,0,-0.1,0.2,-0.1,0.2,-0.3,0.2,-0.2,0.2,0,-0.1,0,0,-0.1,0,0,0.2,-0.1" 
class="s3_40"
>predetermined list of origin languages. Taking a modified example from Figure 11, consider the following </text>

<text 
x="110" 
y="172" 
dx="0,-0.1,0.2,0.2,0,-0.2,0.2,-0.1,0.2,0.2,-0.5,0.2,-0.1,0.2,0,0,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0,0,-0.1,-0.2,0.2,0,-0.1,-0.1,0.2,-0.1,0,-0.1,0,0,-0.1,0.2,0.2,-0.1,0.2,-0.1,0.2,-0.3,-0.2,0.2,0.2,-0.1,0.2,-0.5,0.2,0,0,0,0.2,-0.1,0.2,0,-0.4,-0.1,0,0.2,-0.1,0,0.2,-0.1,0.2,0,0.2,-0.1,0,0.2,-0.1,0.2,0,-0.5,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.1,-0.3" 
class="s3_40"
>sentence and its respective translation and the resulting list of detected languages. </text>

<text 
x="165" 
y="229" 
dx="0,-0.1,0.2,0.2,-0.2,0.2,0,-0.1,0.1,-0.1,0,-0.2,0.2,0,-0.2,0.2,-0.1,0,-0.1,0.2,-0.1,0.2,0.2,-0.1,-0.1,0.2,0,-0.1,0.2,-0.1,-0.2,0.2,-0.1,0,-0.1,-0.1,0,0.2,0.2,0,0,0,0.2,-0.1,0,-0.1,-0.1,0,0,-0.1,-0.2,0.2,-0.1,0,0.2,0.2,-0.1,0,-0.2,0.2,-0.1,0.2,-0.1,0.1,-0.1,0.2,0,-0.4,0.2,0.2,-0.1,0.2,-0.1,-0.1,0,-0.1,0,0.2,0.2,0,-0.5,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,0.2,-0.1,-0.1,0.2,-0.1,-0.2,0.2,-0.3" 
class="s3_40"
>The example in Figure 12 is a notable illustration of how user-defined origin languages can prevent </text>

<text 
x="110" 
y="273" 
dx="0,0,0.2,-0.2,0.2,-0.1,-0.1,-0.1,0,0.2,0.1,0.2,0,-0.1,-0.1,-0.2,0.2,-0.1,0.2,0,0.2,-0.1,0,0,0.2,-0.5,0.2,0,-0.2,0.2,0.2,0,-0.1,-0.1,0.2,-0.1,0.2,0,-0.1,0.2,-0.5,0.2,-0.1,-0.1,0.2,0.2,-0.4,0.2,-0.2,0.2,0.2,0,-0.3,0.2,-0.1,-0.1,0.1,0.2,-0.1,0.2,0,-0.1,-0.2,0.2,-0.1,0.1,-0.1,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0,0.2,-0.1,0.2,0.2,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0.2,0,-0.1,-0.1,0.2,0,-0.1,0.2,-0.3,0.2,-0.2,0.2,0.1,-0.1,-0.1,-0.2" 
class="s3_40"
>the system from detecting the wrong language when it comes to homographs. The second way is the more </text>

<text 
x="110" 
y="317" 
dx="0,0.2,0,-0.1,0.2,0.2,-0.1,0,-0.1,-0.2,0.2,-0.2,0.2,0,0.2,-0.1,-0.1,0.2,-0.1,0,0.2,0,-0.1,-0.1,0,0.2,-0.4,0.2,-0.1,0.2,-0.1,-0.2,0.2,-0.2,0.2,-0.1,-0.1,0,0.2,-0.2,0.2,0,0,-0.1,-0.1,-0.1,0.2,0,-0.1,0.2,-0.1,0.2,0,0.2,-0.1,-0.3,0.2,0,-0.2,0.2,0.2,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0,0.2,0,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.2,0.2,-0.1,0,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.3,0.2,0,0,0.2,-0.1,-0.4,0.2,0,0.2,0,-0.1,-0.1,0.1,-0.1,0,0,-0.1,0.2" 
class="s3_40"
>expensive method of training a neural network to detect the correct language using contextual information </text>

<text 
x="110" 
y="362" 
dx="0,0,-0.1,-0.1,0.1,0.2,0,-0.2,0.2,0.2,-0.1,0.2,-0.1,-0.1,-0.1,-0.2,0.2,-0.1,0,0.2,-0.1,0.2,0,-0.1,-0.1,-0.1,-0.1,0,0.2,0.1,-0.1,0,0.2,-0.1,0.2,-0.1,0,0.2,0,-0.3,0.2,0,-0.2,0.2,0.2,-0.1,0,-0.2,0.2,0,-0.1,0.2,0,-0.1,0.2,0,-0.1,-0.1,-0.4,0.2,0.2,-0.3,0.2,-0.2,0.2,-0.1,-0.1,-0.1,0,0.2,0.1,0.2,0,-0.1,0.2,-0.1,-0.2,0,0.2,-0.1,0,0.2,-0.1,-0.1,-0.2,0.1,-0.1,0.2,-0.1,0.2,0,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.5,0.2,-0.1,-0.1,0.2,0.1,-0.1,-0.1,-0.1,0,0.2" 
class="s3_40"
>from the surrounding words. However, if the aim is to train the system to detect as many languages as Google </text>

<text 
x="110" 
y="406" 
dx="0,-0.1,-0.1,-0.1,0.2,-0.1,0,-0.1,0,0.2,0.2,0,-0.1,0.2,-0.1,-0.1,0,0.2,0.2,0,-0.1,0.2,0,-0.1,-0.1,0.2,-0.1,0,-0.1,0,0.2,-0.3,0.2,0,0.2,-0.1,-0.3,0.2,0,-0.1,0.2,0,-0.1,0.2,-0.1,0.2,-0.1,0.2,0,-0.4,0.2,0.2,-0.1,-0.2,0.2,0,-0.2,0.1,-0.2,-0.2,-0.1,0.2,0.2,-0.1,0.1,-0.1,-0.2,0.2,0,0.2,-0.1,0,0.2,-0.1,-0.1,0,-0.1,0.2,0,-0.1,0.2,0,-0.1,-0.1,0,-0.2,0.2,0,-0.2,0.2,0.2,-0.1,-0.1,-0.1,0,0.2,-0.2,0,0.2,0,0.2,0,-0.5,0.2,0.2,0,-0.1,0.2,-0.5,0.2,0,-0.1,-0.1,-0.1" 
class="s3_40"
>Translate is able to translate, that would require an immense amount of data to train the system, which is a task </text>

<text 
x="110" 
y="450" 
dx="0,0,0.2,-0.1,0,0.2,-0.1,0.2,-0.1,0.2,0,-0.1,-0.2,0.2,-0.1,0,0.2,-0.1,-0.2,0.2,-0.2,0.2,-0.1,0.2,-0.1,0,-0.1,-0.1,0.2,-0.2,0.2,0,0,-0.1,0.2,0,0,-0.1,0" 
class="s3_40"
>that should not be undertaken lightly. </text>



<!-- Any embedded fonts defined here -->
<style type="text/css" ><![CDATA[

@font-face {
	font-family: ArialNovaCond-Bold_d;
	src: url("fonts/ArialNovaCond-Bold_d.woff") format("woff");
}

@font-face {
	font-family: ArialNova-Light_n;
	src: url("fonts/ArialNova-Light_n.woff") format("woff");
}

@font-face {
	font-family: ArialNovaCond-Light_9;
	src: url("fonts/ArialNovaCond-Light_9.woff") format("woff");
}

]]></style>

</svg>
