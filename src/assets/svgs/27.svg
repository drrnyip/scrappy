<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">


<!-- Page 27 -->
<svg x="0" y="0" width="935" height="1210" viewBox="0 0 935 1210" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
style="display: block;margin-left: auto;margin-right: auto;">
<defs>

<style type="text/css"><![CDATA[

.g1_27{
fill: #D9D9D9;
}

.s1_27{
font-size: 18.33px;
font-family: ArialNovaCond-Bold_d;
fill: #5A5A5A;
}
.s2_27{
font-size: 12.10px;
font-family: ArialNova-Light_n;
fill: #7F7F7F;
}
.s3_27{
font-size: 24.57px;
font-family: Calibri-Light_r;
fill: #212934;
}
.s4_27{
font-size: 19.80px;
font-family: Calibri-Light_r;
fill: #212934;
}
.s5_27{
font-size: 18.33px;
font-family: ArialNovaCond-Light_9;
fill: #000000;
}
.s6_27{
font-size: 18.33px;
font-family: ArialNovaCond-Italic_7j;
fill: #000000;
}
.s7_27{
font-size: 18.33px;
font-family: ArialNovaCond-Italic_7j;
fill: #1A0DAB;
}

]]></style>

</defs>
<path d="M0,0
L0,1210
L935,1210
L935,0 Z " 
fill="#FFFFFF" stroke="none" />
<text 
x="110" 
y="1106" 
dx="0,0,0,0.2" 
class="s1_27"
>27 |</text>

<text 
x="141" 
y="1106" 
dx="0,4.3,4.9,0,1.9,0,1.6,0,1.3,0,1.7,0,1.7,0,1.2,0,1.9,0,1.6,4.7,4.9,0,1.3,0,1.7,0,1.6,0,1.5,0,1.6,0,1.9,0,1.2,0,1.5,0,1.9,0,1.5,4.5,4.9,0,1.7,0,1.2,0,1.9,0,1.9,0,1.2,4.5,4.5,0,1.9,0,1.5,4.7,4.9,0,1.3,0,1.5,0,1.9,0,1.5,0,1.5,0,1.5,0,1.5,0,1.9,0,1.3,0,1.9,0,1.6,4.6,4.5,0,1.9,0,1.5,0,1.7,0,1.6,0,1.4,0,1.9,0,1.3,0,1.9,0,1.5,0,1.7,0,1.5,0,1.5,0,1.9" 
class="s2_27"
>A W e b - b a s e d T r a n s l a t i o n S y s t e m f o r M u l t i l i n g u a l C o d e - s w i t c h i n g</text>

<path d="M107.8,1086.4l719.4,0l0,-0.7l-719.4,0l0,0.7Z" class="g1_27" />
<text 
x="110" 
y="133" 
class="s3_27"
>H</text>

<text 
x="126" 
y="133" 
dx="0,1.4,1.6,1.4,1.5,1.6,1.7,1.7,1.3" 
class="s4_27"
>OMOGRAPH </text>

<text 
x="243" 
y="133" 
class="s3_27"
>L</text>

<text 
x="255" 
y="133" 
dx="0,1.4,1.5,1.6,1.3,1.9,1.4,1.7" 
class="s4_27"
>IBRARIES</text>

<text 
x="165" 
y="201" 
dx="0,0.1,-0.1,0.1,-0.1,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,0.2,-0.1,0.2,0,0,0.2,0.2,-0.1,0.2,-0.1,-0.1,0.2" 
class="s5_27"
>Homographs are defined as “</text>

<text 
x="352" 
y="201" 
dx="0,0.2,-0.1,0.2,0,0.1,0,0,0.1,0.1,-0.1,0,0.1,-0.4,0.1,0.1,0.1,0,-0.3,0.2,0.1,-0.1,0,-0.3,0,0.2,0.1,0.2,-0.4,0.2,-0.1,-0.1,0.2,0,0.1,0.1,0,0.2,-0.3,0.2,-0.1,0.1,-0.2,0.1,0,0,0.1,0.1,0,0,0.1,0.1,-0.4,0.2,-0.2,0.2,-0.2,0.2,-0.1,0.1,-0.1,-0.1,-0.1" 
class="s6_27"
>each of two or more words spelled the same but not necessarily </text>

<text 
x="110" 
y="246" 
dx="0,0,0.1,0,0,0,0,0,0.2,0.2,0,-0.3,0.1,0,0.2,-0.3,0.2,-0.1,0.1,0.2,0.1,-0.1,0,0,0.1,0,-0.1,-0.1,-0.1,0,0,0.1,0,-0.1,0,0,0.2,0.1,0.2,0,0.1,0.1,-0.3,0.2,-0.1,0,-0.1,0,0,0.2,0.1,-0.1,0,0,0.1,0,0.1,-0.1,0,-0.1,0,0.2,0.1,-0.2,0.2,0.2,-0.4,0.2,0.2" 
class="s6_27"
>pronounced the same and having different meanings and origins (e.g., </text>

<text 
x="629" 
y="246" 
dx="0,0,0,-0.1" 
class="s7_27"
>bow </text>

<text 
x="665" 
y="246" 
dx="0,-0.1,0,0" 
class="s6_27"
>and </text>

<text 
x="697" 
y="246" 
class="s7_27"
>bow</text>

<text 
x="727" 
y="246" 
dx="0,0.1" 
class="s6_27"
>).</text>

<text 
x="738" 
y="246" 
dx="0,-0.4" 
class="s5_27"
>” </text>

<text 
x="110" 
y="290" 
dx="0,0.1,-0.1,0.1,-0.1,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,0.2,0,-0.1,-0.1,0,-0.1,-0.1,0,0.4,-0.1,0.2,0.2,-0.1,0.2,-0.1,0.2,0,-0.1,0.2,-0.1,0.2,-0.3,0.2,-0.1,0.2,0,-0.1,0.2,0,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,0,-0.1,0.2,-0.1,0,-0.2,-0.1,0.2,0,-0.1,0.2,0,0.2,-0.2,0.2,-0.1,-0.1,0.1,-0.2,0.2,0,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.3,0.2,-0.1,0.2,-0.1,0.2,0,-0.2,0,0,-0.2,0.2,0,0,-0.1,0,-0.1,0.2,-0.1,0,0.2,-0.1,0.2,-0.1,0,0,-0.1,0.2" 
class="s5_27"
>Homographs are typically used to refer to words belonging to the same language, and while lists of English </text>

<text 
x="110" 
y="334" 
dx="0,0.2,-0.1,0.1,-0.1,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,0.2,-0.1,-0.1,0.1,0.1,-0.1,0.2,0.2,-0.1,0.2,-0.1,0.2,-0.4,0.2,-0.1,-0.1,0,0,-0.1,0.2,-0.1,-0.1,-0.1,0,0,-0.1,-0.1,0,0.2,0,0.2,-0.1,-0.1,0.2,-0.1,-0.1,0.1,0,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,0.2,0.2,-0.1,0.1,-0.1,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,0.2,0.2,-0.1,0,-0.3,0.2,-0.2,0.2,0.2,-0.1,0.2,-0.3,0.2,0,-0.2,0.2,-0.1,-0.2,0.2,0,-0.1,-0.1,0.2,-0.1,0.2,-0.2,0.2,0.2,-0.1" 
class="s5_27"
>homographs are common and readily available, cross-language homographs are not. Hence, there was a need </text>

<text 
x="110" 
y="379" 
dx="0,0,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0,0.2,0.2,-0.1,0.2,-0.1,0.2,-0.1,0,-0.1,-0.2,0.2,0,0,-0.1,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0,0.2,-0.1,-0.1,-0.1,0.3,-0.1,0.1,0,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,0.2,0.2,-0.1,0.1,-0.1,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,0,-0.1,-0.1,0.2,0,0.2,-0.2,0.2,-0.1,0.2,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,-0.1,0,0.2,0,0.2,0,-0.1,0.2,-0.1,-0.3,0.2,-0.1,-0.1,0,0.2,-0.1,-0.1,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0,0.2,-0.1" 
class="s5_27"
>to create a custom library of cross-language homographs for the purposes of this study. For scoping </text>

<text 
x="110" 
y="423" 
dx="0,-0.1,0.2,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0,0.2,0.2,0,0,-0.1,-0.1,0,-0.1,0.2,0,0.2,-0.1,0.2,0.2,-0.4,0.2,-0.1,0,-0.1,0,-0.1,0,0.2,-0.1,0.2,0,-0.1,0.2,-0.1,0.2,0,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0,0,0.2,-0.1,0.2,-0.5,0.2,0.1,-0.1,0,-0.1,-0.1,0.1,-0.1,0.2,-0.1,0,0,-0.1,0.2,0.2,-0.1,-0.1,-0.1,-0.1,-0.1,0.1,0.2,-0.1,0.1,-0.1,-0.1,-0.1,0.3,-0.1,0.2,0.2,0,0,-0.1,-0.1,-0.1,-0.1,-0.1,0" 
class="s5_27"
>purposes, efforts were restricted to only creating a Malay-English cross-homograph library. </text>

<text 
x="165" 
y="479" 
dx="0,-0.1,0.2,0.2,0.2,-0.4,0.2,-0.1,0,-0.1,0.2,0.2,-0.1,0.2,0.2,-0.4,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0,0,0.2,-0.1,-0.2,0,0.2,0,-0.1,0.2,0,0,-0.1,-0.1,-0.1,-0.1,-0.1,0.2,0,-0.1,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,0,0.2,-0.3,0.2,-0.1,0.2,0,0.2,-0.1,-0.4,0.1,-0.1,0,0.2,0.2,-0.1,-0.2,0.2,0.2,-0.3,0.2,0,-0.1,0,0,-0.2,0.2,-0.1,0.2,-0.1,-0.1,-0.1,0,-0.1,0,0.2,0,0.2,-0.1,0,0.2,0,-0.1,-0.1,0.2,-0.1,0.2,-0.5,0.2,-0.1" 
class="s5_27"
>The recipe behind creating this library was a brute, but simple one – write a script that takes and </text>

<text 
x="110" 
y="524" 
dx="0,-0.1,-0.1,0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0.2,-0.1,0.2,-0.1,0,0.2,-0.1,0,0,0,0.2,-0.1,0.2,0.2,-0.3,0.2,0,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,-0.1,-0.3,0.2,0,0.2,0,0,-0.2,0.2,0,0,0,-0.3,0.2,-0.1,0,0.2,-0.1,-0.2,-0.1,0.2,0,0.2,0,-0.1,-0.1,-0.1,-0.1,0.2,0,0.2,-0.1,0,0.2,0.2,0,0,-0.1,-0.3,0.2,0,-0.2,0.2,-0.1,-0.1,0,0.2,0.2,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,-0.1,0,0.2,0,0,0,-0.2,0.2,0,0.2,-0.1,-0.3" 
class="s5_27"
>compares corpuses of different languages, while filtering out words that exist in both corpuses. With that </text>

<text 
x="110" 
y="568" 
dx="0,-0.1,-0.1,-0.1,0.3,-0.1,-0.1,-0.1,0.2,0.2,0,0.2,0.2,0.1,-0.4,0.2,-0.1,0,0.2,-0.1,0.2,-0.1,0,0.1,-0.1,0,-0.2,0.2,0.1,-0.1,-0.1,0.2,0,-0.2,-0.1,0.2,-0.1,-0.1,-0.1,0,-0.1,0,0.2,0,-0.1,-0.1,0.2,0,-0.1,0,0,0,0.2,0.2,0.2,0,-0.5,0.2,-0.1,-0.1,-0.1,-0.1,0.1,-0.1,0,0.4,-0.1,0.2,0.2,0,0.2,-0.1,0,0.2,-0.5,0.2,-0.1,-0.1,-0.1,-0.1,0.2,0.2,-0.1,0.2,-0.1,0.2,0,-0.1,-0.1,0.2,0,0.2,-0.1,0.2,0,-0.1,-0.1,-0.1,0.2,0,0,-0.1,0,-0.1,0.2,-0.1,0" 
class="s5_27"
>approach in mind, a simple Node.js script was written to accomplish that purpose and was fed word lists of </text>

<text 
x="110" 
y="613" 
dx="0,-0.1,0.2,-0.1,0,0,-0.1,0.2,0.2,-0.1,0.2,-0.1,0.2,0.1,-0.1,0,-0.1,-0.1,0.2,0,0.2,-0.1,-0.3,0.2,0,0.2,-0.1,-0.2,0.2,-0.1,-0.1,0.2,-0.1,-0.1,0.2,-0.1,0.2,0,-0.1,-0.1,0.1,0.2,-0.1,0.2,-0.1,0,0,-0.1,0,-0.1,0.2,-0.1,-0.1,-0.1,0,0,-0.1,0.2,0,0.2,0.2,-0.1,0.2,-0.1,-0.1,-0.1,0,0,-0.1,-0.1,0,0.2,-0.1,0,0.2,-0.1,0.2,-0.2,0.2,-0.1,-0.1,-0.1,0,-0.1,0,0.2,0,-0.1,-0.1,0.2,-0.1,0.2,0,0,-0.1,0.1,-0.1,0,-0.1,-0.1,0.2,0.2,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,-0.1,0" 
class="s5_27"
>English and Malay that were sourced from publicly available repositories. The script was a two-stage process, </text>

<text 
x="110" 
y="657" 
dx="0,0.2,-0.1,0.1,0.2,0,-0.1,0" 
class="s5_27"
>namely, </text>

<text 
x="165" 
y="713" 
dx="0,-0.1,0,0.2,0.2,0.2,-0.3,0.2,-0.1,0,0.2,-0.1,0.2,-0.1,0.2,-0.1,0,-0.1,-0.1,-0.1,-0.1,-0.1,0.2,-0.1,0.2,-0.1,0.2,-0.1,0.2,-0.1,0,0,-0.1,-0.1,0,0.2,0.2,0,-0.1,-0.1,-0.1,-0.1,0.2,0,0,0,0.2,0,0.2,-0.2,0.2,-0.1,-0.1,0.2,0.2,-0.1,0.2,-0.5,-0.1,0.2,-0.1,0,0,-0.1,0.2,0.2,0,-0.1,0.2,-0.1,0.2,-0.1,-0.1,0.2,0.1,-0.1,0.2,0,-0.1,-0.1,-0.1,0.2,0,0,-0.1,0" 
class="s5_27"
>1. Detect and discard any duplicate words within each respective language’s word list.</text>

<text 
x="165" 
y="748" 
dx="0,-0.1,0,0.2,0.1,-0.1,0.1,-0.1,-0.1,-0.1,0.2,0.2,0.2,-0.1,-0.1,-0.2,0.2,0,-0.1,-0.1,-0.1,0.2,0,-0.1,0.2,-0.1,0.2,0.2,-0.1,-0.1,0.2,-0.1,-0.1,-0.1,0,0.2,-0.1,0,0.2,0,-0.2,0.2,0.2,-0.1,0,-0.2,0.2,-0.1,0.2,0,-0.1,-0.1,-0.1,0.2,0,0,-0.1,0,0.2,0,-0.1,-0.1,0.2,0,-0.1,0.2,0.2,0,0,-0.1,-0.1,0,0.2,0,-0.1,-0.1,-0.1,-0.1,0" 
class="s5_27"
>2. Compare each word to check against the other word list for identical words. </text>



<!-- Any embedded fonts defined here -->
<style type="text/css" ><![CDATA[

@font-face {
	font-family: ArialNovaCond-Bold_d;
	src: url("fonts/ArialNovaCond-Bold_d.woff") format("woff");
}

@font-face {
	font-family: ArialNova-Light_n;
	src: url("fonts/ArialNova-Light_n.woff") format("woff");
}

@font-face {
	font-family: Calibri-Light_r;
	src: url("fonts/Calibri-Light_r.woff") format("woff");
}

@font-face {
	font-family: ArialNovaCond-Light_9;
	src: url("fonts/ArialNovaCond-Light_9.woff") format("woff");
}

@font-face {
	font-family: ArialNovaCond-Italic_7j;
	src: url("fonts/ArialNovaCond-Italic_7j.woff") format("woff");
}

]]></style>

</svg>
